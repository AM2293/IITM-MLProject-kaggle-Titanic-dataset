{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19414fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/amit/python/Industrial_AI_project/IITM_MLops_titanic_dataset_github_clone/IITM-MLProject-kaggle-Titanic-dataset'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8633b28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/amit/python/Industrial_AI_project/IITM_MLops_titanic_dataset_github_clone/IITM-MLProject-kaggle-Titanic-dataset'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "716eab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    root_dir: Path\n",
    "    input_data_file: Path\n",
    "    test_data_file: Path\n",
    "    params_splitratio: list\n",
    "    params_seed: int\n",
    "    params_regParam: list\n",
    "    params_elasticNetParam: list\n",
    "    params_number_of_folds: int\n",
    "    params_sparkSessionTitle: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04db0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Titanic_dataset_analysis import constants as c\n",
    "# from Titanic_dataset_analysis.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "CONFIG_FILE_PATH = Path(\"config/config.yaml\")\n",
    "PARAMS_FILE_PATH = Path(\"params.yaml\")\n",
    "from Titanic_dataset_analysis.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b340094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        print(os.getcwd())\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def model_training_config(self) -> ModelTrainingConfig:\n",
    "        config = self.config.model_training\n",
    "        self.params = self.params\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        # print(f\"Params received under: {self.params} and {self.params.splitratio}\")\n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            input_data_file=config.input_data_file,\n",
    "            test_data_file=config.test_data_file,\n",
    "            params_splitratio=self.params.splitratio,\n",
    "            params_seed=self.params.seed,\n",
    "            params_regParam=self.params.regParam,\n",
    "            params_elasticNetParam=self.params.elasticNetParam,\n",
    "            params_number_of_folds=self.params.number_of_folds,\n",
    "            params_sparkSessionTitle=self.params.sparkSessionTitle\n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333aee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import findspark\n",
    "from pathlib import Path\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from Titanic_dataset_analysis import logger\n",
    "from Titanic_dataset_analysis.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9087603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "    def __init__(self, config: ModelTrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    \n",
    "    def read_file(self):\n",
    "        if not os.path.exists(self.config.input_data_file):\n",
    "            logger.info(f\"File download failed in previous step! Please check the location mentioned : {self.config.input_data_file}\")\n",
    "        else:\n",
    "            logger.info(f\"File already exists of size: {get_size(Path(self.config.input_data_file))}\")\n",
    "\n",
    "        self.df = pd.read_csv(self.config.input_data_file)\n",
    "        logger.info(f\"Processed Input file read from {self.config.input_data_file}\")\n",
    "    \n",
    "    def model_training_and_save_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "        # print(self.config)\n",
    "        # logger.info(f\"Spark session title is: {self.config.params_sparkSessionTitle}\")\n",
    "        spark = SparkSession.builder.appName(self.config.params_sparkSessionTitle).getOrCreate()\n",
    "        spark.sparkContext.setLogLevel(\"WARN\")\n",
    "        \n",
    "        df = spark.read.csv(str(self.config.input_data_file), header=True, inferSchema=True)\n",
    "        # logger.info(df.show())\n",
    "        # Drop Cabin + Name + Ticket (not useful for ML in our setup)\n",
    "        columns_to_drop = [\"Cabin\", \"Name\", \"Ticket\"]\n",
    "        # Categorical feature processing\n",
    "        categorical_cols = [\"Sex\", \"Embarked\"]\n",
    "        indexed_cols = [c + \"_indexed\" for c in categorical_cols]\n",
    "        encoded_cols = [c + \"_encoded\" for c in categorical_cols]\n",
    "\n",
    "        indexers = [StringIndexer(inputCol=c, outputCol=c + \"_indexed\", handleInvalid=\"keep\") for c in categorical_cols]\n",
    "        encoders = [OneHotEncoder(inputCol=ic, outputCol=ec) for ic, ec in zip(indexed_cols, encoded_cols)]\n",
    "\n",
    "        # Vector Assembler\n",
    "        feature_columns = [\n",
    "            \"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\",\n",
    "            \"FamilySize\", \"IsAlone\",\n",
    "            \"Sex_encoded\", \"Embarked_encoded\"\n",
    "        ]\n",
    "        assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "        # Logistic Regression model\n",
    "        lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Survived\")\n",
    "        # -------------------------------\n",
    "        # Pipeline\n",
    "        # -------------------------------\n",
    "        pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])\n",
    "\n",
    "        # -------------------------------\n",
    "        # Train/Test split\n",
    "        # -------------------------------\n",
    "        train_data, test_data = df.drop(*columns_to_drop).randomSplit(self.config.params_splitratio, seed=self.config.params_seed)\n",
    "        test_data.write.mode(\"overwrite\").option(\"header\", True).csv(self.config.test_data_file)\n",
    "        logger.info(f\"Test Data is saved at: {self.config.test_data_file}\")\n",
    "\n",
    "        # -------------------------------\n",
    "        # Param Grid & CrossValidator\n",
    "        # -------------------------------\n",
    "        paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(lr.regParam, self.config.params_regParam) \\\n",
    "            .addGrid(lr.elasticNetParam, self.config.params_elasticNetParam) \\\n",
    "            .build()\n",
    "\n",
    "        # Evaluator\n",
    "        evaluator = BinaryClassificationEvaluator(labelCol=\"Survived\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "        crossval = CrossValidator(estimator=pipeline,\n",
    "                                estimatorParamMaps=paramGrid,\n",
    "                                evaluator=evaluator,\n",
    "                                numFolds=self.config.params_number_of_folds)\n",
    "        cv_model = crossval.fit(train_data)\n",
    "        best_lr = cv_model.bestModel.stages[-1]\n",
    "        logger.info(f\"Best model: {best_lr}\")\n",
    "        \n",
    "        os.makedirs(self.config.root_dir, exist_ok=True)\n",
    "        model_path =f\"{self.config.root_dir}/best_model\"\n",
    "        if os.path.exists(model_path):\n",
    "            cv_model.bestModel.write().overwrite().save(model_path)\n",
    "        else:\n",
    "            cv_model.bestModel.write().save(model_path)\n",
    "        # cv_model.bestModel.write().save(f\"{self.config.root_dir}/best_model\") # .overwrite()\n",
    "        logger.info(f\"Model training done successfully. Model saved at {self.config.root_dir}/best_model\")\n",
    "        \n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3daf1960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amit/python/Industrial_AI_project/IITM_MLops_titanic_dataset_github_clone/IITM-MLProject-kaggle-Titanic-dataset\n",
      "[2025-08-28 12:10:32,234: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-08-28 12:10:32,241: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-08-28 12:10:32,246: INFO: common: created directory at: artifacts]\n",
      "[2025-08-28 12:10:32,251: INFO: common: created directory at: artifacts/model_training]\n",
      "[2025-08-28 12:10:32,253: INFO: 3205805082: File already exists of size: ~ 67 KB]\n",
      "[2025-08-28 12:10:32,263: INFO: 3205805082: Processed Input file read from artifacts/data_preprocessing/titanic_preprocessed.csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/28 12:10:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-28 12:10:32,926: INFO: 3205805082: Test Data is saved at: artifacts/model_training/test_data]\n",
      "[2025-08-28 12:11:59,947: INFO: clientserver: Closing down clientserver connection]\n",
      "[2025-08-28 12:11:59,948: INFO: clientserver: Closing down clientserver connection]\n",
      "[2025-08-28 12:11:59,958: INFO: 3205805082: Best model: LogisticRegressionModel: uid=LogisticRegression_8f633fed113f, numClasses=2, numFeatures=12]\n",
      "[2025-08-28 12:12:01,867: INFO: 3205805082: Model training done successfully. Model saved at artifacts/model_training/best_model]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_training_config = config.model_training_config()\n",
    "    model_training = ModelTraining(config=model_training_config)\n",
    "    model_training.read_file()\n",
    "    model_training.model_training_and_save_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic_end_sem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
